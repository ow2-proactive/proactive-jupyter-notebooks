{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with Proactive Jupyter Kernel and Tensorboard\n",
    "The ActiveEon Jupyter Kernel adds a kernel backend to Jupyter.\n",
    "\n",
    "This kernel interfaces directly with the ProActive scheduler and constructs tasks and workflows to execute them on the fly.\n",
    "\n",
    "With this interface, users can run their code locally and test it using a native python kernel, and by a simple switch to ProActive kernel, run it on remote public or private infrastructures without having to modify the code.\n",
    "\n",
    "See https://github.com/ow2-proactive/proactive-jupyter-kernel for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick start, we recommend the user to run the `#%help()` pragma using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection\n",
    "\n",
    "If you are trying ProActive for the first time, sign up on the [try platform](https://try.activeeon.com/signup.html).\n",
    "\n",
    "Once you receive your login and password, connect to the trial platform using the `#%connect()` pragma.\n",
    "\n",
    "For more information, type: `#%help(pragma=connect)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%connect(url=https://try.activeeon.com:8443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime environment definition\n",
    "\n",
    "The `#%runtime_env()` pragma enable user to define the runtime environment for pipeline execution.\n",
    "\n",
    "The user can select the container type (docker, podman, singularity), the container image, and mount local directories inside container.\n",
    "\n",
    "For more information, type: `#%help(pragma=runtime_env)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%runtime_env(type=docker,image=activeeon/dlm3,mount_host_path=/shared,mount_container_path=/shared,debug=false,verbose=false,force=off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "The main difference between the ProActive and 'native language' kernels resides in the way the memory is accessed\n",
    "during blocks execution. In a common native language kernel, the whole script code (all the notebook blocks) is\n",
    "locally executed in the same shared memory space; whereas the ProActive kernel will execute each created task in an\n",
    "independent process. In order to facilitate the transition from native language to ProActive kernels, we included the\n",
    "pragma `#%import()`. This pragma gives the user the ability to add libraries that are common to all created tasks, and\n",
    "thus relative distributed processes, that are implemented in the same native script language.\n",
    "\n",
    "The import pragma is used as follows:\n",
    "\n",
    "`#%import([language=SCRIPT_LANGUAGE])`.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "#%import(language=Python)\n",
    "import os\n",
    "import pandas\n",
    "```\n",
    "\n",
    "NOTE: If the language is not specified, Python is considered as default language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%import()\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _import_data_ task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=import_data,export=[dataframe_json])\n",
    "dataset_url = \"https://activeeon-public.s3.eu-west-2.amazonaws.com/datasets/vehicle_silhouette_weka_dataset.csv\"\n",
    "dataframe = pd.read_csv(dataset_url)\n",
    "\n",
    "dataframe_json = dataframe.to_json(orient='split').encode()\n",
    "compressed_data = bz2.compress(dataframe_json)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _cross_validation_ task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=cross_validation,dep=[import_data],import=[dataframe_json],export=[nested_scores_json])\n",
    "dataframe = pd.read_json(dataframe_json, orient='split')\n",
    "\n",
    "label_column = \"vehicle_class\"\n",
    "dataframe_train = dataframe.drop(label_column, axis=1, inplace=False)\n",
    "dataframe_label = dataframe[label_column]\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2', 'l1'])\n",
    "\n",
    "# We will use a Logistic Classifier with \"rbf\" kernel\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200, random_state=0)\n",
    "\n",
    "# Choose cross-validation techniques for the inner and outer loops,\n",
    "# independently of the dataset.\n",
    "# E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "inner_cv = KFold(n_splits=10, shuffle=True, random_state=random.randint(0,9))\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=random.randint(0,9))\n",
    "\n",
    "# Non_nested parameter search and scoring\n",
    "clf = RandomizedSearchCV(estimator=logistic, param_distributions=distributions, cv=inner_cv)\n",
    "clf.fit(dataframe_train, dataframe_label)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "nested_scores = cross_val_score(clf, X=dataframe_train, y=dataframe_label, cv=outer_cv)\n",
    "\n",
    "# Print scores\n",
    "print(\"nested cross-validation scores:\\n\", nested_scores)\n",
    "print(\"average of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(nested_scores.mean(), nested_scores.std()))\n",
    "\n",
    "# Save scores on Tensorboard\n",
    "# writer = SummaryWriter(\"./logs\")\n",
    "PA_JOB_ID = variables.get(\"PA_JOB_ID\")\n",
    "TENSORBOARD_LOG_PATH = \"/shared/tensorboard/job_id_\" + str(PA_JOB_ID)\n",
    "os.makedirs(TENSORBOARD_LOG_PATH)\n",
    "writer = SummaryWriter(TENSORBOARD_LOG_PATH)\n",
    "for idx, nested_score in enumerate(nested_scores):\n",
    "    writer.add_scalar('Logistic_Regression_Scores', nested_score, idx)\n",
    "writer.close()\n",
    "\n",
    "# save the model to disk\n",
    "#filename = '/shared/logistic_regression_model.sav'\n",
    "#pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "nested_scores_json = json.dumps(nested_scores.tolist())\n",
    "result = nested_scores_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the job pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%draw_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting the job to the scheduler\n",
    "\n",
    "To submit the job to the ProActive Scheduler, the user has to use the `#%submit_job()` pragma:\n",
    "\n",
    "```python\n",
    "#%submit_job()\n",
    "```\n",
    "\n",
    "If the job is not created, or is not up-to-date, the `#%submit_job()` creates a new job named as the old one.\n",
    "To provide a new name, use the same pragma and provide a name as parameter:\n",
    "\n",
    "```python\n",
    "#%submit_job([name=JOB_NAME])\n",
    "```\n",
    "\n",
    "If the job's name is not set, the ProActive kernel uses the current notebook name, if possible, or gives a random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%submit_job(name=ML_Pipeline_Tensorboard_Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting results and outputs\n",
    "\n",
    "After the execution of a ProActive workflow, two outputs can be obtained,\n",
    "* results: values that have been saved in the \n",
    "[task result variable](https://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_task_result),\n",
    "* console outputs: classic outputs that have been displayed/printed \n",
    "\n",
    "To get task results, please use the `#%get_task_result()` pragma by providing the task name, and either the job ID or\n",
    "the job name:\n",
    "\n",
    "```python\n",
    "#%get_task_result([job_id=JOB_ID], [job_name=JOB_NAME], task_name=TASK_NAME)\n",
    "```\n",
    "\n",
    "The result(s) of all the tasks of a job can be obtained with the `#%get_job_result()` pragma, by providing the job name\n",
    "or the job ID:\n",
    "\n",
    "```python\n",
    "#%get_job_result([job_id=JOB_ID], [job_name=JOB_NAME])\n",
    "```\n",
    "\n",
    "To get and display console outputs of a task, you can use the `#%print_task_output()` pragma in the following\n",
    "way:\n",
    "\n",
    "```python\n",
    "#%print_task_output([job_id=JOB_ID], [job_name=JOB_NAME], task_name=TASK_NAME)\n",
    "```\n",
    "\n",
    "Finally, the  `#%print_job_output()` pragma allows to print all job outputs, by providing the job name or the job ID:\n",
    "\n",
    "```python\n",
    "#%print_job_output([job_id=JOB_ID], [job_name=JOB_NAME])\n",
    "```\n",
    "\n",
    "NOTE: If neither `job_name` nor the `job_id` are provided, the last submitted job is selected by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%print_task_output(task_name=cross_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProActive",
   "language": "python",
   "name": "proactive"
  },
  "language_info": {
   "codemirror_mode": "python",
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
