{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Automation with Proactive Jupyter Kernel\n",
    "The ActiveEon Jupyter Kernel adds a kernel backend to Jupyter.\n",
    "\n",
    "This kernel interfaces directly with the ProActive scheduler and constructs tasks and workflows to execute them on the fly.\n",
    "\n",
    "With this interface, users can run their code locally and test it using a native python kernel, and by a simple switch to ProActive kernel, run it on remote public or private infrastructures without having to modify the code.\n",
    "\n",
    "See https://github.com/ow2-proactive/proactive-jupyter-kernel for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick start, we recommend the user to run the `#%help()` pragma using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection\n",
    "\n",
    "If you are trying ProActive for the first time, sign up on the [try platform](https://try.activeeon.com/signup.html).\n",
    "\n",
    "Once you receive your login and password, connect to the trial platform using the `#%connect()` pragma.\n",
    "\n",
    "For more information, type: `#%help(pragma=connect)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%connect(url=https://try.activeeon.com:8443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime environment definition\n",
    "\n",
    "The `#%runtime_env()` pragma enable user to define the runtime environment for pipeline execution.\n",
    "\n",
    "The user can select the container type (docker, podman, singularity), the container image, and mount local directories inside container.\n",
    "\n",
    "For more information, type: `#%help(pragma=runtime_env)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%runtime_env(type=docker,image=activeeon/dlm3,mount_host_path=/shared,mount_container_path=/shared,debug=false,verbose=false,force=off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "The main difference between the ProActive and 'native language' kernels resides in the way the memory is accessed\n",
    "during blocks execution. In a common native language kernel, the whole script code (all the notebook blocks) is\n",
    "locally executed in the same shared memory space; whereas the ProActive kernel will execute each created task in an\n",
    "independent process. In order to facilitate the transition from native language to ProActive kernels, we included the\n",
    "pragma `#%import()`. This pragma gives the user the ability to add libraries that are common to all created tasks, and\n",
    "thus relative distributed processes, that are implemented in the same native script language.\n",
    "\n",
    "The import pragma is used as follows:\n",
    "\n",
    "`#%import([language=SCRIPT_LANGUAGE])`.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "#%import(language=Python)\n",
    "import os\n",
    "import pandas\n",
    "```\n",
    "\n",
    "NOTE: If the language is not specified, Python is considered as default language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%import()\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _import_ task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=import,export=[dataframe_json])\n",
    "boston = load_boston()\n",
    "dataframe_load = pd.DataFrame(boston.data)\n",
    "dataframe_load.columns = boston.feature_names \n",
    "data_label = boston.target\n",
    "dataframe = dataframe_load.assign(LABEL=data_label)\n",
    "\n",
    "dataframe_json = dataframe.to_json(orient='split').encode()\n",
    "compressed_data = bz2.compress(dataframe_json)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _split_ task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=split,dep=[import],import=[dataframe_json],export=[X_train_json,X_test_json])\n",
    "dataframe = pd.read_json(dataframe_json, orient='split')\n",
    "\n",
    "X_train, X_test = train_test_split(dataframe, test_size=30)\n",
    "\n",
    "X_train_json = X_train.to_json(orient='split').encode()\n",
    "X_test_json = X_test.to_json(orient='split').encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _train_ task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=train,dep=[split],import=[X_train_json],export=[filename,columns])\n",
    "# Fit the model on 33%\n",
    "columns = \"LABEL\"\n",
    "\n",
    "X_train = pd.read_json(X_train_json, orient='split')\n",
    "\n",
    "dataframe_train = X_train.drop(columns, axis=1, inplace=False)\n",
    "dataframe_label = X_train.filter(columns, axis=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(dataframe_train, dataframe_label)\n",
    "\n",
    "# save the model to disk\n",
    "filename = '/shared/finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _predict_ task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=predict,dep=[train,split],import=[columns,filename,X_test_json])\n",
    "X_test = pd.read_json(X_test_json, orient='split')\n",
    "\n",
    "dataframe_test = X_test.drop(columns, axis=1, inplace=False)\n",
    "dataframe_label = X_test.filter(columns, axis=1)\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(dataframe_test, dataframe_label)\n",
    "\n",
    "print('The prediction result is = ' + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the job pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%draw_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting the job to the scheduler\n",
    "\n",
    "To submit the job to the ProActive Scheduler, the user has to use the `#%submit_job()` pragma:\n",
    "\n",
    "```python\n",
    "#%submit_job()\n",
    "```\n",
    "\n",
    "If the job is not created, or is not up-to-date, the `#%submit_job()` creates a new job named as the old one.\n",
    "To provide a new name, use the same pragma and provide a name as parameter:\n",
    "\n",
    "```python\n",
    "#%submit_job([name=JOB_NAME])\n",
    "```\n",
    "\n",
    "If the job's name is not set, the ProActive kernel uses the current notebook name, if possible, or gives a random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%submit_job(name=ML_Pipeline_Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting results and outputs\n",
    "\n",
    "After the execution of a ProActive workflow, two outputs can be obtained,\n",
    "* results: values that have been saved in the \n",
    "[task result variable](https://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_task_result),\n",
    "* console outputs: classic outputs that have been displayed/printed \n",
    "\n",
    "To get task results, please use the `#%get_task_result()` pragma by providing the task name, and either the job ID or\n",
    "the job name:\n",
    "\n",
    "```python\n",
    "#%get_task_result([job_id=JOB_ID], [job_name=JOB_NAME], task_name=TASK_NAME)\n",
    "```\n",
    "\n",
    "The result(s) of all the tasks of a job can be obtained with the `#%get_job_result()` pragma, by providing the job name\n",
    "or the job ID:\n",
    "\n",
    "```python\n",
    "#%get_job_result([job_id=JOB_ID], [job_name=JOB_NAME])\n",
    "```\n",
    "\n",
    "To get and display console outputs of a task, you can use the `#%print_task_output()` pragma in the following\n",
    "way:\n",
    "\n",
    "```python\n",
    "#%print_task_output([job_id=JOB_ID], [job_name=JOB_NAME], task_name=TASK_NAME)\n",
    "```\n",
    "\n",
    "Finally, the  `#%print_job_output()` pragma allows to print all job outputs, by providing the job name or the job ID:\n",
    "\n",
    "```python\n",
    "#%print_job_output([job_id=JOB_ID], [job_name=JOB_NAME])\n",
    "```\n",
    "\n",
    "NOTE: If neither `job_name` nor the `job_id` are provided, the last submitted job is selected by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%print_task_output(task_name=predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProActive",
   "language": "python",
   "name": "proactive"
  },
  "language_info": {
   "codemirror_mode": "python",
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
