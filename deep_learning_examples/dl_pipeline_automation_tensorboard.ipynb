{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Pipeline with Proactive Jupyter Kernel and Tensorboard\n",
    "The ActiveEon Jupyter Kernel adds a kernel backend to Jupyter.\n",
    "\n",
    "This kernel interfaces directly with the ProActive scheduler and constructs tasks and workflows to execute them on the fly.\n",
    "\n",
    "With this interface, users can run their code locally and test it using a native python kernel, and by a simple switch to ProActive kernel, run it on remote public or private infrastructures without having to modify the code.\n",
    "\n",
    "This notebook was based on the following one:\n",
    "\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter09_part01_image-segmentation.ipynb\n",
    "\n",
    "See https://github.com/ow2-proactive/proactive-jupyter-kernel for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick start, we recommend the user to run the `#%help()` pragma using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection\n",
    "\n",
    "If you are trying ProActive for the first time, sign up on the [try platform](https://try.activeeon.com/signup.html).\n",
    "\n",
    "Once you receive your login and password, connect to the trial platform using the `#%connect()` pragma.\n",
    "\n",
    "For more information, type: `#%help(pragma=connect)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%connect(url=https://try.activeeon.com:8443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime environment definition\n",
    "\n",
    "The `#%runtime_env()` pragma enable user to define the runtime environment for pipeline execution.\n",
    "\n",
    "The user can select the container type (docker, podman, singularity), the container image, and mount local directories inside container.\n",
    "\n",
    "For more information, type: `#%help(pragma=runtime_env)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%runtime_env(type=docker,image=activeeon/tensorflow,nvidia_gpu=false,mount_host_path=/shared,mount_container_path=/shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", for best performance on NVIDIA GPUs use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%runtime_env(type=docker,image=activeeon/tensorflow:latest-gpu,nvidia_gpu=true,mount_host_path=/shared,mount_container_path=/shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "The main difference between the ProActive and 'native language' kernels resides in the way the memory is accessed\n",
    "during blocks execution. In a common native language kernel, the whole script code (all the notebook blocks) is\n",
    "locally executed in the same shared memory space; whereas the ProActive kernel will execute each created task in an\n",
    "independent process. In order to facilitate the transition from native language to ProActive kernels, we included the\n",
    "pragma `#%import()`. This pragma gives the user the ability to add libraries that are common to all created tasks, and\n",
    "thus relative distributed processes, that are implemented in the same native script language.\n",
    "\n",
    "The import pragma is used as follows:\n",
    "\n",
    "`#%import([language=SCRIPT_LANGUAGE])`.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "#%import(language=Python)\n",
    "import os\n",
    "import pandas\n",
    "```\n",
    "\n",
    "NOTE: If the language is not specified, Python is considered as default language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%import()\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except:\n",
    "    install(\"Pillow==8.4.0\")\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    install(\"matplotlib==3.5.1\")\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def path_to_input_image(path):\n",
    "    return img_to_array(load_img(path, target_size=img_size))\n",
    "\n",
    "def path_to_target(path):\n",
    "    img = img_to_array(load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n",
    "    img = img.astype(\"uint8\") - 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _download_dataset_ task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=download_dataset,language=Linux_Bash)\n",
    "MODELS_PATH=\"/shared/models\"\n",
    "mkdir -p $MODELS_PATH\n",
    "\n",
    "DATASET_PATH=\"/shared/datasets/pets\"\n",
    "if [ ! -d \"$DATASET_PATH\" ]; then\n",
    "    mkdir -p $DATASET_PATH\n",
    "    apt update && apt install -y wget\n",
    "    wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz -P $DATASET_PATH\n",
    "    wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz -P $DATASET_PATH\n",
    "    tar -xf $DATASET_PATH/images.tar.gz -C $DATASET_PATH\n",
    "    tar -xf $DATASET_PATH/annotations.tar.gz -C $DATASET_PATH\n",
    "    echo \"Done\"\n",
    "else\n",
    "    echo \"$DATASET_PATH already exists\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _train_model_ task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=train_model,dep=[download_dataset])\n",
    "DATASET_PATH=\"/shared/datasets/pets\"\n",
    "input_dir = os.path.join(DATASET_PATH, \"images\")\n",
    "target_dir = os.path.join(DATASET_PATH, \"annotations/trimaps\")\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [os.path.join(input_dir, fname)\n",
    "     for fname in os.listdir(input_dir)\n",
    "     if fname.endswith(\".jpg\")])\n",
    "target_paths = sorted(\n",
    "    [os.path.join(target_dir, fname)\n",
    "     for fname in os.listdir(target_dir)\n",
    "     if fname.endswith(\".png\") and not fname.startswith(\".\")])\n",
    "\n",
    "img_size = (200, 200)\n",
    "num_imgs = len(input_img_paths)\n",
    "\n",
    "random.Random(1337).shuffle(input_img_paths)\n",
    "random.Random(1337).shuffle(target_paths)\n",
    "\n",
    "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
    "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
    "for i in range(num_imgs):\n",
    "    input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
    "    targets[i] = path_to_target(target_paths[i])\n",
    "\n",
    "num_val_samples = 1000\n",
    "train_input_imgs = input_imgs[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_input_imgs = input_imgs[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = get_model(img_size=img_size, num_classes=3)\n",
    "model.summary() # Total params: 2,880,643\n",
    "\n",
    "# Setup optmizer and loss function\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "# Setup Tensorboard\n",
    "if 'variables' in globals():\n",
    "    PA_JOB_ID = variables.get(\"PA_JOB_ID\")\n",
    "    PA_TRIAL_ID = variables.get(\"PA_TASK_REPLICATION\") # or PA_TASK_ID\n",
    "    TENSORBOARD_LOG_PATH = \"/shared/tensorboard/job_id_\" + str(PA_JOB_ID) + \"_t\" + str(PA_TRIAL_ID)\n",
    "else:\n",
    "    TENSORBOARD_LOG_PATH = \"./logs/trial\"\n",
    "Path(TENSORBOARD_LOG_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"/shared/models/oxford_segmentation.keras\", save_best_only=True),\n",
    "    keras.callbacks.TensorBoard(log_dir=TENSORBOARD_LOG_PATH)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_input_imgs, train_targets,\n",
    "                    epochs=3,\n",
    "                    callbacks=callbacks,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(val_input_imgs, val_targets))\n",
    "\n",
    "print(\"Average training loss: \", np.average(history.history['loss']))\n",
    "print(\"Average validation loss: \", np.average(history.history['val_loss']))\n",
    "\n",
    "# epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
    "# loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "# plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "# plt.title(\"Training and validation loss\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the _predict_ task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%task(name=predict,dep=[train_model])\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "\n",
    "path = '/shared/datasets/pets/images/chihuahua_1.jpg'\n",
    "img_size = (200, 200)\n",
    "test_image = path_to_input_image(path)\n",
    "\n",
    "model = keras.models.load_model(\"/shared/models/oxford_segmentation.keras\")\n",
    "\n",
    "pred = model.predict(np.expand_dims(test_image, 0))[0]\n",
    "\n",
    "mask = np.argmax(pred, axis=-1)\n",
    "mask *= 127\n",
    "\n",
    "shutil.copyfile(path, \"/shared/input.png\")\n",
    "mpimg.imsave(\"/shared/prediction.png\", mask)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the job pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%draw_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting the job to the scheduler\n",
    "\n",
    "To submit the job to the ProActive Scheduler, the user has to use the `#%submit_job()` pragma:\n",
    "\n",
    "```python\n",
    "#%submit_job()\n",
    "```\n",
    "\n",
    "If the job is not created, or is not up-to-date, the `#%submit_job()` creates a new job named as the old one.\n",
    "To provide a new name, use the same pragma and provide a name as parameter:\n",
    "\n",
    "```python\n",
    "#%submit_job([name=JOB_NAME])\n",
    "```\n",
    "\n",
    "If the job's name is not set, the ProActive kernel uses the current notebook name, if possible, or gives a random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%submit_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting results and outputs\n",
    "\n",
    "After the execution of a ProActive workflow, two outputs can be obtained,\n",
    "* results: values that have been saved in the \n",
    "[task result variable](https://doc.activeeon.com/latest/user/ProActiveUserGuide.html#_task_result),\n",
    "* console outputs: classic outputs that have been displayed/printed \n",
    "\n",
    "To get task results, please use the `#%get_task_result()` pragma by providing the task name, and either the job ID or\n",
    "the job name:\n",
    "\n",
    "```python\n",
    "#%get_task_result([job_id=JOB_ID], [job_name=JOB_NAME], task_name=TASK_NAME)\n",
    "```\n",
    "\n",
    "The result(s) of all the tasks of a job can be obtained with the `#%get_job_result()` pragma, by providing the job name\n",
    "or the job ID:\n",
    "\n",
    "```python\n",
    "#%get_job_result([job_id=JOB_ID], [job_name=JOB_NAME])\n",
    "```\n",
    "\n",
    "To get and display console outputs of a task, you can use the `#%print_task_output()` pragma in the following\n",
    "way:\n",
    "\n",
    "```python\n",
    "#%print_task_output([job_id=JOB_ID], [job_name=JOB_NAME], task_name=TASK_NAME)\n",
    "```\n",
    "\n",
    "Finally, the  `#%print_job_output()` pragma allows to print all job outputs, by providing the job name or the job ID:\n",
    "\n",
    "```python\n",
    "#%print_job_output([job_id=JOB_ID], [job_name=JOB_NAME])\n",
    "```\n",
    "\n",
    "NOTE: If neither `job_name` nor the `job_id` are provided, the last submitted job is selected by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%print_job_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProActive",
   "language": "python",
   "name": "proactive"
  },
  "language_info": {
   "codemirror_mode": "python",
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
